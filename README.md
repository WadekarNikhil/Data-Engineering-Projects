# ğŸ›  Data Engineering Projects

## ğŸ“Œ Overview
This repository contains projects focused on **data engineering**, including **ETL pipelines, database management, data transformation, and data processing** using **SQL, PySpark, and SFTP automation**.

## ğŸ“‚ Projects Included

### 1ï¸âƒ£ PySpark & SQL Data Processing
- **Project:** PySpark data processing & MySQL connectivity.
- **Technologies:** PySpark, SQL, MySQL, MongoDB.
- **Files:**
  - `mongo.py` (Reads data from MongoDB into PySpark)
  - `mysql_spark.py` (Connects MySQL with PySpark)
  - `pyspark_first_demo.py` (Reads text files using PySpark)
  - `sql.py` (Processes MySQL data - Spotify dataset)
  - `demo.py` & `Demo1.py` (Reads JSON & CSV using PySpark)

### 2ï¸âƒ£ SFTP Automation Scripts
- **Project:** Secure file transfer automation using SFTP & SSH.
- **Technologies:** Python, Paramiko.
- **Files:**
  - `new11.py` (SSH file download script)
  - `testsftp.py` (SSH file upload script)

## ğŸš€ Technologies Used
- **SQL (MySQL, PostgreSQL, MongoDB)**
- **PySpark & Data Processing**
- **SFTP, Paramiko for Secure File Transfers**
- **Cloud Data Engineering Concepts**

## ğŸ“œ How to Use
1. Clone this repository:
   ```bash
   git clone https://github.com/yourusername/Data-Engineering-Projects.git
   ```
2. Install dependencies (if applicable):
   ```bash
   pip install pymysql pyspark paramiko
   ```
3. Run the respective scripts based on project needs.

## ğŸ¤ Contributions
Feel free to fork this repository and contribute by adding improvements or new **Data Engineering projects**.
